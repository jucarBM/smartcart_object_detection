{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Que compone el entrenamiento\n",
        "- Labelmap\n",
        "- Tfrecords (train, test)\n",
        "- Modelo pre-entrenado\n",
        "- Configurtar pipeline.config"
      ],
      "metadata": {
        "id": "qUsH428GgSs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Instalamos los paquetes necesarios para que funcione desde la Colab\n",
        "!pip install avro-python3\n",
        "!pip install \n",
        "!pip install tf_slim==1.1.0\n",
        "!pip install tf-models-official\n",
        "!pip install lvis\n",
        "!pip install tensorflow_io==0.23.1\n",
        "!pip install keras==2.7.0\n",
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LwUcdTdynsy",
        "outputId": "07890684-6dc8-4b5b-adc1-9fa1b5df71be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Building wheels for collected packages: avro-python3\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=557a1427328a1b060232f8e737163f259fa150597b2e7493d6d1852b4533a618\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "Successfully built avro-python3\n",
            "Installing collected packages: avro-python3\n",
            "Successfully installed avro-python3-1.10.2\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n",
            "Collecting tf_slim==1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim==1.1.0) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim==1.1.0) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.11)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n",
            "Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.5.0)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.21.6)\n",
            "Collecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.28)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.4)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 32.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 47.7 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.3.5)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.31.5)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.56.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.64.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2021.10.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.4)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (13.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (4.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.24.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.14.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.44.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (2019.12.20)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (1.7.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (21.4.0)\n",
            "Building wheels for collected packages: py-cpuinfo, seqeval\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=0ba9aff14b2379cbf85669f105888f116b02d6a317eaddb19fea37be7046a32c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=75af5648ae9aec0255892c9b82353e18e23f3e587811913e98ca43fe6892d20e\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built py-cpuinfo seqeval\n",
            "Installing collected packages: tf-estimator-nightly, portalocker, colorama, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 opencv-python-headless-4.5.5.64 portalocker-2.4.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.21.6)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.28)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.1.0->lvis) (4.2.0)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "Collecting tensorflow_io==0.23.1\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.24.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.24.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.24.0\n",
            "Successfully installed tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1\n",
            "Collecting keras==2.7.0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.7.0\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.5.5.64\n",
            "    Uninstalling opencv-python-headless-4.5.5.64:\n",
            "      Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qqNeTsIzYs69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9fa7ba-1a5f-4e43-86c9-b0cb0cf45fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/models\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,575 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Err:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [84.5 kB]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,733 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [909 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [942 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,167 kB]\n",
            "Reading package lists... Done\n",
            "W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\n",
            "E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease' is no longer signed.\n",
            "N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n",
            "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "#!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz \\\n",
        "    -O /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD3_LgPLg0sy",
        "outputId": "2271332e-9ca3-4dd3-d830-1ea9d33aca07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-29 01:19:28--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.148.128, 2607:f8b0:4001:c54::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.148.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/ssd_mobile 100%[===================>]  19.56M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-04-29 01:19:29 (266 MB/s) - ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "output_path = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "print(\"La carpeta se almaceno en {}\".format(output_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYkVKTKRlyTy",
        "outputId": "2d83d53b-f9c2-413f-9ff8-13dafad5804a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n",
            "La carpeta se almaceno en /content/models/research/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_training = '/content/ssd_mobilenet'\n",
        "os.mkdir(path_training)"
      ],
      "metadata": {
        "id": "u0RiC8DgmGlq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_config = \"{}/pipeline.config\".format(output_path)\n",
        "target_config = \"{}/pipeline.config\".format(path_training)\n",
        "shutil.copyfile(source_config, target_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NAEJx_PLmmfS",
        "outputId": "c0d3280d-676d-4408-c4fe-8f81683dad14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ssd_mobilenet/pipeline.config'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "hRxSaMzMqI3f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(target_config)"
      ],
      "metadata": {
        "id": "GUei86bFqRbc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(target_config, \"r\") as f:\n",
        "  proto_str = f.read()\n",
        "  text_format.Merge(proto_str, pipeline_config)"
      ],
      "metadata": {
        "id": "fvIudsM9rE_a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las rutas en donde se encuentra los TFRecords y el label map para agregarlos al archivo de configuración del pipeline.config\n",
        "label_map_pbtxt_fname = \"/content/cars_label_map.pbtxt\"\n",
        "train_record_fname = \"/content/cars_train.tfrecord\"\n",
        "test_record_fname = \"/content/cars_test.tfrecord\""
      ],
      "metadata": {
        "id": "eut_ATIxr0WY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de clases del modelo\n",
        "pipeline_config.model.ssd.num_classes = 2\n",
        "\n",
        "# El tamaño del batch size, entre más grande mas costo computacional va a necesitar en el proceso de entrenamiento, pero a su vez entrenara más rapido.\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "\n",
        "# Donde almacenaremos los resultados del entrenamiento\n",
        "pipeline_config.train_config.fine_tune_checkpoint =\"{}/checkpoint/ckpt-0\".format(output_path)\n",
        "\n",
        "# Qué tipo de deteción aplicaremos (Object detection)\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "\n",
        "# Dirección del label map\n",
        "pipeline_config.train_input_reader.label_map_path = label_map_pbtxt_fname\n",
        "\n",
        "# Dirección del train TFRecord\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = train_record_fname\n",
        "\n",
        "# Dirección del label map\n",
        "pipeline_config.eval_input_reader[0].label_map_path = label_map_pbtxt_fname\n",
        "\n",
        "# Dirección del test TFRecord\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_fname"
      ],
      "metadata": {
        "id": "Q6pXGjKbsnUC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(target_config, \"wb\") as f:\n",
        "  f.write(config_text)"
      ],
      "metadata": {
        "id": "eaAI0bpxtOL6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 5000\n",
        "model_dir = \"/content/ssd_mobilenet\"\n",
        "\n",
        "# Utilizamos directamente la libreria de object detection para ejecutar el script model_main_tf2\n",
        "# Los argumentos principales son el archivo de configuración, la ubicación del modelo y la cantidad de steps que ejecutará.\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "--pipeline_config_path={target_config} \\\n",
        "--model_dir={model_dir} \\\n",
        "--num_train_steps={num_steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP-szIoOuHqe",
        "outputId": "9da53822-ae3f-44da-9818-5474c7699740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-29 01:20:00.366758: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0429 01:20:00.408984 140422678472576 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0429 01:20:00.413682 140422678472576 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0429 01:20:00.413877 140422678472576 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0429 01:20:00.587341 140422678472576 deprecation.py:343] From /content/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/cars_train.tfrecord']\n",
            "I0429 01:20:00.601153 140422678472576 dataset_builder.py:162] Reading unweighted datasets: ['/content/cars_train.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/cars_train.tfrecord']\n",
            "I0429 01:20:00.601371 140422678472576 dataset_builder.py:79] Reading record datasets for input file: ['/content/cars_train.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0429 01:20:00.601515 140422678472576 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0429 01:20:00.601656 140422678472576 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0429 01:20:00.608548 140422678472576 deprecation.py:343] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0429 01:20:00.655949 140422678472576 deprecation.py:343] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0429 01:20:09.178240 140422678472576 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0429 01:20:12.943412 140422678472576 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0429 01:20:15.174654 140422678472576 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.815480 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.817049 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.819958 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.821167 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.824042 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.825242 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.828135 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.829315 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.832233 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0429 01:20:54.833395 140422678472576 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0429 01:20:55.613750 140417915074304 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.585s\n",
            "I0429 01:21:53.890074 140422678472576 model_lib_v2.py:707] Step 100 per-step time 0.585s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21179181,\n",
            " 'Loss/localization_loss': 0.17405935,\n",
            " 'Loss/regularization_loss': 0.15495992,\n",
            " 'Loss/total_loss': 0.54081106,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0429 01:21:53.890686 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.21179181,\n",
            " 'Loss/localization_loss': 0.17405935,\n",
            " 'Loss/regularization_loss': 0.15495992,\n",
            " 'Loss/total_loss': 0.54081106,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.197s\n",
            "I0429 01:22:13.291546 140422678472576 model_lib_v2.py:707] Step 200 per-step time 0.197s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22211525,\n",
            " 'Loss/localization_loss': 0.15555492,\n",
            " 'Loss/regularization_loss': 0.15500449,\n",
            " 'Loss/total_loss': 0.5326747,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0429 01:22:13.291893 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.22211525,\n",
            " 'Loss/localization_loss': 0.15555492,\n",
            " 'Loss/regularization_loss': 0.15500449,\n",
            " 'Loss/total_loss': 0.5326747,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.196s\n",
            "I0429 01:22:32.927557 140422678472576 model_lib_v2.py:707] Step 300 per-step time 0.196s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1563494,\n",
            " 'Loss/localization_loss': 0.1584263,\n",
            " 'Loss/regularization_loss': 0.154843,\n",
            " 'Loss/total_loss': 0.4696187,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0429 01:22:32.927962 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.1563494,\n",
            " 'Loss/localization_loss': 0.1584263,\n",
            " 'Loss/regularization_loss': 0.154843,\n",
            " 'Loss/total_loss': 0.4696187,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.197s\n",
            "I0429 01:22:52.623968 140422678472576 model_lib_v2.py:707] Step 400 per-step time 0.197s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09697087,\n",
            " 'Loss/localization_loss': 0.076240875,\n",
            " 'Loss/regularization_loss': 0.15454367,\n",
            " 'Loss/total_loss': 0.32775542,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0429 01:22:52.624341 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.09697087,\n",
            " 'Loss/localization_loss': 0.076240875,\n",
            " 'Loss/regularization_loss': 0.15454367,\n",
            " 'Loss/total_loss': 0.32775542,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.196s\n",
            "I0429 01:23:12.182244 140422678472576 model_lib_v2.py:707] Step 500 per-step time 0.196s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12783425,\n",
            " 'Loss/localization_loss': 0.11692522,\n",
            " 'Loss/regularization_loss': 0.15424676,\n",
            " 'Loss/total_loss': 0.39900625,\n",
            " 'learning_rate': 0.053333}\n",
            "I0429 01:23:12.182607 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.12783425,\n",
            " 'Loss/localization_loss': 0.11692522,\n",
            " 'Loss/regularization_loss': 0.15424676,\n",
            " 'Loss/total_loss': 0.39900625,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.195s\n",
            "I0429 01:23:31.654650 140422678472576 model_lib_v2.py:707] Step 600 per-step time 0.195s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16411676,\n",
            " 'Loss/localization_loss': 0.11264013,\n",
            " 'Loss/regularization_loss': 0.15387012,\n",
            " 'Loss/total_loss': 0.430627,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0429 01:23:31.655056 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.16411676,\n",
            " 'Loss/localization_loss': 0.11264013,\n",
            " 'Loss/regularization_loss': 0.15387012,\n",
            " 'Loss/total_loss': 0.430627,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.195s\n",
            "I0429 01:23:51.154439 140422678472576 model_lib_v2.py:707] Step 700 per-step time 0.195s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13915786,\n",
            " 'Loss/localization_loss': 0.048765346,\n",
            " 'Loss/regularization_loss': 0.15340188,\n",
            " 'Loss/total_loss': 0.3413251,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0429 01:23:51.154892 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.13915786,\n",
            " 'Loss/localization_loss': 0.048765346,\n",
            " 'Loss/regularization_loss': 0.15340188,\n",
            " 'Loss/total_loss': 0.3413251,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.196s\n",
            "I0429 01:24:10.780499 140422678472576 model_lib_v2.py:707] Step 800 per-step time 0.196s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13159485,\n",
            " 'Loss/localization_loss': 0.15138258,\n",
            " 'Loss/regularization_loss': 0.15306087,\n",
            " 'Loss/total_loss': 0.43603832,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0429 01:24:10.780879 140422678472576 model_lib_v2.py:708] {'Loss/classification_loss': 0.13159485,\n",
            " 'Loss/localization_loss': 0.15138258,\n",
            " 'Loss/regularization_loss': 0.15306087,\n",
            " 'Loss/total_loss': 0.43603832,\n",
            " 'learning_rate': 0.069333196}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de los resultados con TensorBoard"
      ],
      "metadata": {
        "id": "6OxlNoAk6sxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/ssd_mobilenet\""
      ],
      "metadata": {
        "id": "A1FYZ7mH6pjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exportación de modelo\n",
        "\n",
        "Exportamos nuestro modelo para poder utilizarlo en cualquier otro momento.\n"
      ],
      "metadata": {
        "id": "PiCIYdbq6YA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = \"/content/fine_tuned_model\"\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "--input_type image_tensor \\\n",
        "--pipeline_config_path {target_config} \\\n",
        "--trained_checkpoint_dir {model_dir} \\\n",
        "--output_directory {output_directory}"
      ],
      "metadata": {
        "id": "rMp-EINC6fCU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}